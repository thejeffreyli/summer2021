{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zach Sherman Code to Generate Series of RADAR Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import animation\n",
    "import numpy as np\n",
    "import pyart # added import\n",
    "\n",
    "files = sorted(glob.glob('/Users/nivarazin/Local/NAISE/OneDrive_2_7-15-2021/*.nc'))\n",
    "\n",
    "\n",
    "### REFLECTIVITY PLOTS ###\n",
    "def animate_ref(nframe):\n",
    "    plt.clf()\n",
    "    \n",
    "    radar = pyart.io.read(files[nframe])\n",
    "#     Add filter\n",
    "#     gatefilter = pyart.correct.GateFilter(radar)\n",
    "#     gatefilter.exclude_below('reflectivity', 15)\n",
    "    display = pyart.graph.RadarDisplay(radar)\n",
    "    # Delete radar after use to save memory.\n",
    "    del radar\n",
    "    # tmp fix, for flipping file that is reversed.\n",
    "    if nframe == 1: \n",
    "        reverse_xaxis = True # probably don't need this for LIDAR data\n",
    "    else:\n",
    "        reverse_xaxis = False # probably don't need this for LIDAR data\n",
    "    display.plot_rhi('reflectivity', reverse_xaxis=reverse_xaxis)# , gatefilter=gatefilter) # added filter\n",
    "#     plt.ylim(0, 25) # zoom in to plot region\n",
    "fig = plt.figure(figsize=(24, 12))\n",
    "anim_klot = animation.FuncAnimation(fig, animate_ref,\n",
    "                                    frames=len(files))\n",
    "anim_klot.save('/Users/nivarazin/Local/NAISE/mpl_data_animation.gif', \n",
    "               writer='pillow', fps=1)\n",
    "plt.close()\n",
    "\n",
    "\n",
    "### DIFFERENTIAL REFLECTIVITY PLOTS ###\n",
    "def animate_diff_ref(nframe):\n",
    "    plt.clf()\n",
    "    radar = pyart.io.read(files[nframe])\n",
    "    display = pyart.graph.RadarDisplay(radar)\n",
    "    # Delete radar after use to save memory.\n",
    "    del radar\n",
    "    #tmp fix, for flipping file that is reversed.\n",
    "    if nframe == 1:\n",
    "        reverse_xaxis = True\n",
    "    else:\n",
    "        reverse_xaxis = False\n",
    "    display.plot_rhi('differential_reflectivity', reverse_xaxis=reverse_xaxis)\n",
    "    #plt.ylim(0, 25)\n",
    "fig = plt.figure(figsize=(24, 12))\n",
    "anim_klot = animation.FuncAnimation(fig, animate_diff_ref,\n",
    "                                    frames=len(files))\n",
    "anim_klot.save('/Users/nivarazin/Desktop/NAISE/diff_ref_uncropped_animation.gif',\n",
    "               writer='pillow', fps=1)\n",
    "plt.close()\n",
    "\n",
    "\n",
    "### VELOCITY PLOTS ###\n",
    "def animate_vel(nframe):\n",
    "    plt.clf()\n",
    "    radar = pyart.io.read(files[nframe])\n",
    "    display = pyart.graph.RadarDisplay(radar)\n",
    "    # Delete radar after use to save memory.\n",
    "    del radar\n",
    "    #tmp fix, for flipping file that is reversed.\n",
    "    if nframe == 1:\n",
    "        reverse_xaxis = True\n",
    "    else:\n",
    "        reverse_xaxis = False\n",
    "    display.plot_rhi('mean_doppler_velocity', reverse_xaxis=reverse_xaxis)\n",
    "    #plt.ylim(0, 25)\n",
    "fig = plt.figure(figsize=(24, 12))\n",
    "anim_klot = animation.FuncAnimation(fig, animate_vel,\n",
    "                                    frames=len(files))\n",
    "anim_klot.save('/Users/nivarazin/Desktop/NAISE/vel__uncropped_animation.gif',\n",
    "               writer='pillow', fps=1)\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Individual  (cropped) .PNGs of RADAR Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For automated cropping of .pngs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nivarazin/opt/anaconda3/envs/pyart_env/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "# this removed legend, graph borders that interfere with optical flow algorithms\n",
    "\n",
    "def crop_center(im_name):\n",
    "    im = Image.open(im_name)\n",
    "    \n",
    "    # Setting the points for cropped image\n",
    "    left = 217\n",
    "    top = 105\n",
    "    right = 1287\n",
    "    bottom = 755\n",
    "    \n",
    "    return im.crop((left, top, right, bottom))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate individual .png's (snapshots from .gifs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import animation\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pyart\n",
    "import imageio\n",
    "\n",
    "path = '/Users/nivarazin/Local/NAISE/Dense Optical Flow/diff_ref data/filtered_pngs/'\n",
    "files = sorted(glob.glob('/Users/nivarazin/Local/NAISE/corcsaprrhi/*.nc'))\n",
    "\n",
    "for i in range(len(files)): \n",
    "    file = files[i]\n",
    "    radar = pyart.io.read(file)\n",
    "    \n",
    "    # apply gate filter, allowing only reflectivity data from 15 m above sensor through, for example\n",
    "#     gatefilter = pyart.correct.GateFilter(radar)\n",
    "#     gatefilter.exclude_below('differential_reflectivity', 0)\n",
    "    \n",
    "    fig = plt.figure(figsize=(24, 12))\n",
    "    display = pyart.graph.RadarDisplay(radar)\n",
    "    \n",
    "    # tmp fix, for flipping file that is reversed.\n",
    "    if i == 1: \n",
    "        reverse_xaxis = True # probably don't need this for LIDAR data\n",
    "    else:\n",
    "        reverse_xaxis = False # probably don't need this for LIDAR data\n",
    "    \n",
    "    display.plot_rhi('differential_reflectivity', reverse_xaxis=reverse_xaxis, gatefilter= gatefilter)\n",
    "    \n",
    "    # for \"zooming in\" on region in radar scan\n",
    "#     plt.ylim(0, 25) \n",
    "    \n",
    "    # save plot\n",
    "    im_name = path + 'diff_ref_' + str(i) + '.png'\n",
    "    plt.savefig(im_name)\n",
    "\n",
    "    # crop out legend, plot border, axis labels, etc.\n",
    "    im_new = crop_center(im_name) # RUN CELL ABOVE\n",
    "    im_new.save(im_name)\n",
    "    \n",
    "    del radar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert RADAR .PNGs to .MP4 / .AVI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenCV's optical flow algorithms work on movies, hence needing to convert still images to .mp4/.avi files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nivarazin/opt/anaconda3/envs/pyart_env/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "image_folder = '/Users/nivarazin/Local/NAISE/Dense Optical Flow/diff_ref data/filtered_pngs/'\n",
    "video_name = image_folder+'filtered_0_unzoomed.avi'\n",
    "\n",
    "images = [img for img in os.listdir(image_folder) if img.endswith(\".png\")]\n",
    "frame = cv2.imread(os.path.join(image_folder, images[0]))\n",
    "height, width, layers = frame.shape\n",
    "\n",
    "video = cv2.VideoWriter(video_name, 0, 1, (width,height))\n",
    "\n",
    "for image in images:\n",
    "    video.write(cv2.imread(os.path.join(image_folder, image)))\n",
    "cv2.destroyAllWindows()\n",
    "video.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenCV Dense Optical Flow Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modified from: https://docs.opencv.org/3.4/d4/dee/tutorial_optical_flow.html\n",
    "\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "\n",
    "\n",
    "image_foder = '/Users/nivarazin/Local/NAISE/Dense Optical Flow/diff_ref data/filtered_pngs/'\n",
    "# Read in .avi file\n",
    "cap = cv.VideoCapture(cv.samples.findFile(image_foder+\"filtered_0_unzoomed.avi\"))\n",
    "ret, frame1 = cap.read()\n",
    "\n",
    "print(ret)\n",
    "\n",
    "prvs = cv.cvtColor(frame1,cv.COLOR_BGR2GRAY)\n",
    "hsv = np.zeros_like(frame1)\n",
    "hsv[...,1] = 255\n",
    "\n",
    "ret, frame2 = cap.read() # added here\n",
    "  \n",
    "counter=0\n",
    "while(ret): #changed from while(1)\n",
    "    print(ret)\n",
    "    # ret, frame2 = cap.read() #removed here\n",
    "    next = cv.cvtColor(frame2,cv.COLOR_BGR2GRAY)\n",
    "    \n",
    "    flow = cv.calcOpticalFlowFarneback(prvs,next, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "    mag, ang = cv.cartToPolar(flow[...,0], flow[...,1])\n",
    "    hsv[...,0] = ang*180/np.pi/2\n",
    "    hsv[...,2] = cv.normalize(mag,None,0,255,cv.NORM_MINMAX)\n",
    "    bgr = cv.cvtColor(hsv,cv.COLOR_HSV2BGR)\n",
    "    cv.imshow('frame2',bgr)\n",
    "    \n",
    "    # added for .gif generation: (still images)\n",
    "    temp = image_folder + 'dense_filtered_25_ref_zoomed_' + str(counter) + '.png'\n",
    "    #temp = 'LK_diff_ref_cropped_output_opticalhsv_.png'\n",
    "    cv.imwrite(temp, bgr) # added\n",
    "    counter += 1\n",
    "    \n",
    "    # Not sure what code below did (infinite waiting loop on last image); so, I commented it out (k always = 255)\n",
    "    #k = cv.waitKey(30) & 0xff # print(cv.waitKey(30))    \n",
    "    #if k == 27:\n",
    "    #    break\n",
    "    #elif k == ord('s'):\n",
    "    \n",
    "    #cv.imwrite('opticalfb.png',frame2) # show image on GUI pop up\n",
    "    cv.imwrite('dense_filtered_0_unzoomed.png', bgr)\n",
    "    \n",
    "    prvs = next\n",
    "    \n",
    "    ret, frame2 = cap.read() # added here\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenCV Lucas-Kanade Optical Flow Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# modified from: https://docs.opencv.org/3.4/d4/dee/tutorial_optical_flow.html\n",
    "\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import argparse\n",
    "\n",
    "# parser.add_argument('image', type=str, help='path to image file')\n",
    "# args = parser.parse_args()\n",
    "\n",
    "image_folder = '/Users/nivarazin/Local/NAISE/temp LK unfiltered cropped/unzoomed/'\n",
    "video_name = '/Users/nivarazin/Local/NAISE/temp LK unfiltered cropped/unfiltered_cropped_unzoomed.avi'\n",
    "\n",
    "# cap = cv.VideoCapture(args.image) \n",
    "cap = cv.VideoCapture(cv.samples.findFile(video_name))\n",
    "\n",
    "# params for ShiTomasi corner detection\n",
    "feature_params = dict( maxCorners = 15,\n",
    "                       qualityLevel = 0.4,\n",
    "                       minDistance = 2,\n",
    "                       blockSize = 7 )\n",
    "# Parameters for lucas kanade optical flow\n",
    "lk_params = dict( winSize  = (15,15),\n",
    "                  maxLevel = 2,\n",
    "                  criteria = (cv.TERM_CRITERIA_EPS | cv.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "\n",
    "\n",
    "# Create some random colors\n",
    "color = np.random.randint(0,255,(100,3)) #255-->200\n",
    "\n",
    "# Take first frame and find corners in it\n",
    "ret, old_frame = cap.read()\n",
    "\n",
    "old_gray = cv.cvtColor(old_frame, cv.COLOR_BGR2GRAY)\n",
    "# print(cv.COLOR_BGR2GRAY, type(cv.COLOR_BGR2GRAY))\n",
    "# print(type(old_gray))\n",
    "\n",
    "# mask bounds\n",
    "# range_start = 0 # added\n",
    "# range_end = 350 # added\n",
    "# range_id = str(range_start) + '_' + str(range_end)\n",
    "\n",
    "\n",
    "# Preparing mask --> [range_start:range_end]\n",
    "p0 = cv.goodFeaturesToTrack(old_gray, mask = None, **feature_params) # default, no mask\n",
    "# mask regions for edge detection:\n",
    "#p0 = cv.goodFeaturesToTrack(cv.cvtColor(old_frame[range_start:range_end], cv.COLOR_BGR2GRAY), mask = cv.cvtColor(old_frame[range_start:range_end], cv.COLOR_BGR2GRAY), **feature_params)\n",
    "\n",
    "\n",
    "# Create a mask image for drawing purposes\n",
    "mask = np.zeros_like(old_frame)\n",
    "counter = 0\n",
    "\n",
    "ret,frame = cap.read() # added\n",
    "while(ret): # changed condition form 1 --> ret\n",
    "    # ret,frame = cap.read() # removed\n",
    "    print(ret) # ret is boolean that says if image was read correctly\n",
    "    frame_gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Calculate optical flow\n",
    "    p1, st, err = cv.calcOpticalFlowPyrLK(old_gray, frame_gray, p0, None, **lk_params)\n",
    "    \n",
    "    # Select good points\n",
    "    if p1 is not None:\n",
    "        good_new = p1[st==1]\n",
    "        good_old = p0[st==1]\n",
    "   \n",
    "    # draw the tracks\n",
    "    for i,(new,old) in enumerate(zip(good_new, good_old)):\n",
    "        a,b = new.ravel()\n",
    "        c,d = old.ravel()\n",
    "        mask = cv.line(mask, (int(a),int(b)),(int(c),int(d)), color[i].tolist(), 2) #[255,0,0] OR color[i].tolist()\n",
    "        frame = cv.circle(frame,(int(a),int(b)),5,color[i].tolist(),-1)\n",
    "    \n",
    "    # applying mask\n",
    "    img = cv.add(frame, mask)\n",
    "    \n",
    "#   cv.imshow('frame',img)\n",
    "\n",
    "    temp = image_folder + str(counter) + '.png' # + range_id\n",
    "    cv.imwrite(temp, img) # added\n",
    "    counter += 1\n",
    "    \n",
    "    # Not sure what code below did (infinite waiting loop on last image); so, I commented it out (k always = 255)\n",
    "#     k = cv.waitKey(1000) & 0xff\n",
    "#     if k == 27:\n",
    "#         break\n",
    "        \n",
    "    # Now update the previous frame and previous points\n",
    "    old_gray = frame_gray.copy()\n",
    "    p0 = good_new.reshape(-1,1,2)\n",
    "    \n",
    "    ret,frame = cap.read() # added\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dense Pyramid Lucas-Kanade OF (alternate algo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-contrib-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modified from: https://learnopencv.com/optical-flow-in-opencv/#optical-flow-types\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def dense_optical_flow(method, video_path, params=[], to_gray=False):\n",
    "\n",
    "    # Read the video and first frame\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    ret, old_frame = cap.read()\n",
    "\n",
    "    # crate HSV & make Value a constant\n",
    "    hsv = np.zeros_like(old_frame)\n",
    "    hsv[..., 1] = 255\n",
    "\n",
    "    # Preprocessing for exact method\n",
    "    if to_gray:\n",
    "        old_frame = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    counter = 0\n",
    "    while True:\n",
    "        # Read the next frame\n",
    "        ret, new_frame = cap.read()\n",
    "        frame_copy = new_frame\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Preprocessing for exact method\n",
    "        if to_gray:\n",
    "            new_frame = cv2.cvtColor(new_frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Calculate Optical Flow\n",
    "        flow = method(old_frame, new_frame, None, *params)\n",
    "\n",
    "        # Encoding: convert the algorithm's output into Polar coordinates\n",
    "        mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "        # Use Hue and Value to encode the Optical Flow\n",
    "        hsv[..., 0] = ang * 180 / np.pi / 2\n",
    "        hsv[..., 2] = cv2.normalize(mag, None, 0, 255, cv2.NORM_MINMAX)\n",
    "\n",
    "        # Convert HSV image into BGR for demo\n",
    "        bgr = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
    "        cv2.imshow(\"frame\", frame_copy)\n",
    "        cv2.imshow(\"optical flow\", bgr)\n",
    "        \n",
    "        temp = save + str(counter) + '.png' # + range_id\n",
    "        cv2.imwrite(temp, bgr) # added\n",
    "        counter += 1\n",
    "\n",
    "        k = cv2.waitKey(25) & 0xFF\n",
    "        if k == 27:\n",
    "            break\n",
    "\n",
    "        # Update the previous frame\n",
    "        old_frame = new_frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "video_path = '/Users/nivarazin/Local/NAISE/ref_cropped_unfiltered_unzoomed_pngs/ref_cropped_unfiltered_unzoomed.avi'\n",
    "save = '/Users/nivarazin/Local/NAISE/calcOpticalFlowSparseToDense/ref_cropped_unfiltered_unzoomed_'\n",
    "method = cv2.optflow.calcOpticalFlowSparseToDense\n",
    "dense_optical_flow(method, video_path, to_gray=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make .GIF from Optical Flow .PNGs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nivarazin/opt/anaconda3/envs/pyart_env/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "#!pip install imageio\n",
    "\n",
    "import imageio\n",
    "#range_id = '0_650'\n",
    "images = []\n",
    "base_png = '/Users/nivarazin/Local/NAISE/temp LK unfiltered cropped/zoomed/base pngs/ref_0.png'\n",
    "path = '/Users/nivarazin/Local/NAISE/Dense Optical Flow/diff_ref data/filtered_pngs/'\n",
    "F0 = path+'dense_filtered_0_ref_zoomed_0.png'\n",
    "F1 = path+'dense_filtered_0_ref_zoomed_1.png'\n",
    "F2 = path+'dense_filtered_0_ref_zoomed_2.png'\n",
    "F3 = path+'dense_filtered_0_ref_zoomed_3.png'\n",
    "# Bad hard coding (fix):\n",
    "filenames = [\n",
    "             #base_png, base_png, base_png, base_png, base_png, base_png, # for sparse LK OF\n",
    "             F0, F0, F0, F0, F0, F0,\n",
    "             F1, F1, F1, F1, F1, F1,\n",
    "             F2, F2, F2, F2, F2, F2, \n",
    "             F3, F3, F3, F3, F3, F3]\n",
    "for filename in filenames:\n",
    "    images.append(imageio.imread(filename))\n",
    "imageio.mimsave(path+'filtered_0_unzoomed.gif', images)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
