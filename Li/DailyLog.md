## Week 1: First Week 

<br />

### June 1, 2021 (Day 1)

Updates:
* Finished Day 1 of orientation
* Met with Dr. Nicola Ferrier and Dr. Scott Collis for group meeting, talked about project topics and some suggestions for light readings and prep.
* Still figuring things out around the lab.

To Do:
* Look into PyImage and other sources to help with OpenCV.

Thoughts:
* Very excited to work with my new team and to learn new material!

<br />

### June 2, 2021 (Day 2)

Updates:
* Finished Day 2 of orientation.
* Met with Dr. Todd Munson and student connect group - aka .
* PyImage is expensive. Found an alternative to learn OpenCV through [YT tutorials](https://www.youtube.com/watch?v=kdLM6AOd2vc&list=PLS1QulWo1RIa7D1O6skqDQ-JZ1GGHKK-K). Will be binging those.
* Managed to run Docker on Windows 10 Home. Confirmed this through following shared [Docker YT tutorial](https://www.youtube.com/watch?v=7S73WERRqO4).

To Do:
* Pre-SULI Survey, other Argonne forms/trainings, finish Getting Started portion of Waggle GitHub.
* Crash course through OpenCV.

Thoughts:
* Still getting accustomed to remote work and SULI/Argonne.

<br />

### June 3, 2021 (Day 3)

Updates:
* Attended welcome meeting by Dr. Rick Stevens and CELS Student Lecture by Dr. Sarah Owens.
* Approved of LCRC account. Set up SSH successfully (after lots of trial and error).

To Do:
* Training modules for working at Argonne. Lots of them.
* Look at past SAGE projects.


<br />

### June 4, 2021 (Day 4)

Updates:
* Met with Dr. Nicola Ferrier to discuss project topic. Will be tinkering around with OpenCV and other derivatives of it, finding ways to measure snow using sticks. For greater applications, finding how to do a more semi-supervised approach to machine learning in terms of training data.
* Project Guiding Question: Can we use ML but reduce the human effort required for training?
* Project Goal: Snow level detection with NEON poles.

To Do:
* Complete training modules for working at Argonne. Lots of them.
* Seek inspiration for OpenCV ideas from online repositories and literature. 
* Look into CVAT.
* Find educational sources for ML packages, specifically Deep Learning and/or PyTorch for OpenCV.

Thoughts:
* Excited and nervous to have project idea and goals laid out. Will be a big learning curve for computer vision, but I am confident I will overcome it.

<br />

## Week 2: Learning OpenCV 

<br />


### June 7, 2021 (Day 5)

Updates:
* Finished most or all of training.
* Forked Summer 2021 Waggle GitHub repository and cloned onto my PC.
* Completed OpenCV YT tutorials up to 13. YT user generously provided his code, and I have been tinkering around with them. 
* Topics Covered: Reading Images (3), Reading Input Videos (4), Drawing Shapes (5), Setting Camera Parameters (6), Setting Text (7), Mouse Events (8-9), Image Operations (10), Bitwise Operations (11), Trackbar (12), Object Detection and Tracking with HSV (13)

To Do:
* Continue studying and working on OpenCV tutorials.

<br />

### June 8, 2021 (Day 6)
Updates:
* Completed OpenCV YT tutorials up to 16.
* Topics Covered: Simple Image Thresholding (14), Adaptive Thresholding (15), matplotlib (16).

To Do:
* Continue studying and working on OpenCV tutorials.

<br />

### June 9, 2021 (Day 7)
Updates:
* Attended seminar 'When and How Do I Go to Graduate School?' by Dr. Bruce A. Lindvall, Assistant Dean of Graduate Admissions at Northwestern McCormick School of Engineering
* Attended student connect session with 'Caffeinated Camels'
* Attended introductory writing coach session led by Dr. Robert Boomsma. Talked about scientific writing, story telling, and resources. 
* Felt feverish throughout the day and wanted to rest. Did not get much work done on tutorial.

To Do:
* Continue studying and working on OpenCV tutorials.

<br />

### June 10, 2021 (Day 8)
Updates:
* Attended seminar on 'Tensor Contraction' by Dr. Victor Anisimov.
* Completed OpenCV YT tutorials up to 20.
* Topics Covered: Morphological Transformations (17), Smoothing Images (18), Image Gradients and Edge Detection (19), Canny Edge Detection (20).
* Started developing code for the NEON poles. Worked with object detection with HSV first, results were very unclear. Then I applied edge detection methods: laPlacian, sobelX, sobelY, sobelCombined (both x and y), and canny. After adjustments, Canny appeared best. The rough code and results from these trials can be found in this [link](https://drive.google.com/drive/folders/1oUQMWgmphOGV-kxji74zP_XyLX4kVBNS?usp=sharing).

To Do:
* Continue studying and working on OpenCV tutorials.
* Gather more image data from NEON.

<br />

### June 11, 2021 (Day 9)
Updates:
* Meeting with Computer Vision Group. Discussed results from initial tests on NEON poles. Next steps will be line detection and image segmentation.
* Acquired access to [repository](https://phenocam.sr.unh.edu/webcam/browse/NEON.D19.HEAL.DP1.00042/) of NEON poles images. Will be useful for training models.
* Worked and finalized PowerPoint Presentation for Monday.

To Do:
* Continue studying and working on OpenCV tutorials.
* Look into deep learning and other tools, potentially. 

<br />

## Week 3: Learning OpenCV  

<br />


### June 14, 2021 (Day 10)
Updates:
* Meeting with entire group. Presented introductory research project [PowerPoint](https://drive.google.com/drive/folders/1k9J21eadIv8XXBE6BPbYZGX86StaYNdX?usp=sharing).
* Completed OpenCV YT tutorials up to 24.
* Topics Covered: Image Pyramid (21), Image Blending (22), Find and Draw Contours (23), Motion Detection and Tracking with Contours (24).

To Do:
* Continue studying and working on OpenCV tutorials.
* Need to ramp up project pace! Exciting things ahead.

<br />

### June 15, 2021 (Day 11)
Updates:
* Meeting with Computer Vision Group. Discussed plans for this week: line detection and template matching.
* Completed OpenCV YT tutorials up to 29.
* Topics Covered: Detect Simple Geometric Shapes (25), Histograms (26), Template Matching (27), Hough Line Transform (28), HoughLines Method (29).

To Do:
* Continue studying and working on OpenCV tutorials.
* Look into annotation tools and deep learning with CV.
* Read up on math behind CV.

<br />

### June 16, 2021 (Day 12)
Updates:
* Attended seminar on 'Overcoming Imposter Syndrome' by Dr. Adia Gooden.
* Meeting with Student Connects Group. Created 'Caffeinated Camels' backgroup wallpaper.
* Completed OpenCV YT tutorials up to 33.
* Topics Covered: Probablistic Hough Line Transform (30), Road Lane Line Detection (31-33).
* Studied the math behind Hough Line Transformation. 
    (1) [OpenCV Python Tutorial For Beginners 28 - Hough Line Transform Theory](https://www.youtube.com/watch?v=7m-RVJ6ABsY&list=PLS1QulWo1RIa7D1O6skqDQ-JZ1GGHKK-K&index=33)
    (2) [MathWorks - Hough Lines](https://www.mathworks.com/help/images/ref/houghlines.html#d123e95197) 
    (3) [The Hough Transform](https://aishack.in/tutorials/hough-transform-basics/)
    (4) [Hough Line Transform](https://docs.opencv.org/3.4/d9/db0/tutorial_hough_lines.html])
* Played around with probablistic Hough line transformation function. Made short video of photos compiled from repository. Developed a program to detect the line of one NEON pole throughout the different frames. Can be found [here](https://drive.google.com/drive/folders/1fOfLs8i4FzrBH7bSJ4PWUD8Vy_NuZhHP?usp=sharing).

To Do:
* Continue studying and working on OpenCV tutorials.

<br />

### June 17, 2021 (Day 13)
Updates:
* Meeting with Computer Vision Group. Discussed progress for this week.
* Attended seminar on 'Atmospheric Sciences' by Dr. Scott Collis.
* Readings:
    (1) [GitHub: Snow Depth Measurement](https://github.com/NRCANTerry/snow-depth). 
    (2) [Python 60 lines of code use OpenCV to identify snow depth](https://programmer.help/blogs/python-60-lines-of-code-use-opencv-to-identify-snow-depth.html). 
    (3) [python,opencv,Line 60 of Python USES OpenCV to identify snow depths](https://www.codestudyblog.com/sfb2002b1/0225213741.html). 
    (4) [Fully automated snow depth measurements from time-lapse images applying a convolutional neural network](https://www.sciencedirect.com/science/article/abs/pii/S0048969719341907).             
* PyImageSearch Computer Vision and Deep Learning Crash Course, [Day 1: Face detection with OpenCV and deep learning](https://www.pyimagesearch.com/2018/02/26/face-detection-with-opencv-and-deep-learning/).
* Worked on Jupyter Notebook for creating ROIs in each image and detecting three poles via Canny/Hough methods. 
* Used this [site](https://blog.electroica.com/select-roi-or-multiple-rois-bounding-box-in-opencv-python/) as a reference.

To Do:
* Continue studying and working on OpenCV tutorials.

<br />

### June 18, 2021 (Day 14)
Updates:
* Finished [Jupyter Notebook](https://drive.google.com/drive/folders/1mxQ1gy5yxggR_cSxEcwic3UQj3heDHjZ?usp=sharing) for creating ROIs in each image and detecting three poles via Canny/Hough methods.
* PyImageSearch Computer Vision and Deep Learning Crash Course, [Day 2: OpenCV Tutorial: A Guide to Learn OpenCV](https://www.pyimagesearch.com/2018/07/19/opencv-tutorial-a-guide-to-learn-opencv/).
* Read [journal](https://www.ipol.im/pub/art/2012/gjmr-lsd/article.pdf) shared by Nicola on a more efficient line detection method: Line Segment Detector (LSD). 

To Do:
* Continue studying and working on OpenCV tutorials.
* Look into convolutional neural networks (CNN) and OpenCV, Mask R-CNN.

<br />

## Week 4: Line Detection for Snow Rods

<br />


### June 21, 2021 (Day 15)
Updates:
* Meeting with entire group. Viewed presentations of rest of the group members.
* Started 'Deep Learning With Tensorflow 2.0, Keras and Python' YT playlist. Watched videos 1 - 11. 
* Topics Covered: Intro (1), Why DL (2), Neuron (3), Neural Network (4), Install TF2.0 (5), TF v. PT v. Keras (6), NN for Digits Classification (7), Activation Functions (8), Derivatives (9), Matrix Basics (10), Loss or Cost Function (11). 

To Do:
* Continue studying and working on OpenCV tutorials and project.

<br />

### June 22, 2021 (Day 16)
Updates:
* Meeting with Computer Vision Group. Discussed necessary changes to direction for my project. Was introduced to alternative method (createFastLineDetector()) to LSD that can be implemented into Python since the original LSD is no longer available in OpenCV. Shared earlier paper on "Fully automated snow depth measurements."
* Primary project question: How can we use OpenCV and ML to avoid manual lableling (i.e. reduce human effort)?
* Application project question: How can we use computer vision to detect and measure snow cover?
* Looked into YOLOV3 examples and CVAT for labeling. 
* Sources:
    (1) [Yolo v3 TensorFlow 2](https://www.youtube.com/playlist?list=PLbMO9c_jUD473OgrKYYMLRMEz-XZjG--n). 
    (2) [Getting Started with CVAT - Annotation for Computer Vision](https://blog.roboflow.com/cvat/). 
* Installed TensorNets and looked into the JNs on YOLOV3 sent by Colin. The JNs can be found [here](https://drive.google.com/drive/folders/1YeVMBhJsXxq6vf4H_Aih-QoapwaWhnxW?usp=sharing).

To Do:
* Continue studying and working on OpenCV tutorials and project.

<br />

### June 23, 2021 (Day 17)
Updates:
* Attended seminar on 'Connecting to a Career Through LinkedIn' by Harrell Townsend.
* Met with Nicole for one-on-one 'office hours,' since I felt very lost on project. We discussed the ROI/HoughP notebook. She helped me by clarifying what should be done next. I will be furthering my ROI model on images with varying features (i.e. snowing, cloudy, sunny, etc...), essentially testing different parameters and building the training set for the ML algorithm. CNN can be used later for determining snow cover. 
* TLDR: We will be using ML rather than manual image labeling. DL can be easily applied later for snow detection.
* The tentative project outline:
    (1) Input Images
    (2) ML algorithm classifies images. The classification identifies parameters for edge detection/LSD.
    (3) Run appropriate LSD program to identify lines (i.e. the three poles).
    (4) TBD: probably run CNN
* Worked on implementing createFastLineDetector() into the ROI/HoughP JN. The initial line detections have been very weak. 
* Sources:
    (1) [Fast line detector](https://docs.opencv.org/4.5.2/df/ded/group__ximgproc__fast__line__detector.html). 
    (2) [How to use OpenCV4's FastLineDetector in Python 3?](https://stackoverflow.com/questions/57017927/how-to-use-opencv4s-fastlinedetector-in-python-3). 
    (3) [A new fast line detection algorithm](https://ieeexplore.ieee.org/document/1627457)
* Created database with images with varing features. Identified potential features: grass, snow, day, night, light, season, time.
* Meeting with Student Connects Group. Presented 1-2 minute introduction to current research.
 
To Do:
* Continue studying and working on OpenCV tutorials and project.

<br />

### June 24, 2021 (Day 18)
Updates:
* Meeting with Computer Vision Group. Discussed progress for this week.
* Tinkered with ways to improve createFastLineDetector() for detection of poles. The middle pole is the only one with 'perfect' line detection, mainly because it is facing towards the camera. The left and right poles are at an angle, so only the lines closest to the camera can be detected. 
* Found someone asking a similar question on [StackOverflow](https://stackoverflow.com/questions/57080937/increase-accuracy-of-detecting-lines-using-opencv). The recommended procedure is (1) Convert image to grayscale, (2) Apply a sharpening kernel (3) Threshold image, (4) Perform morphological operations to smooth/filter image. Unfortunately, this did not perform as well on the snow images as it did on their examples. The sharpening created more noise from the snow.
* Tried blurring methods as suggested by this [source](https://www.pyimagesearch.com/2021/04/28/opencv-smoothing-and-blurring/). The results improved significantly as background noises were reduced. This enabled the lines to be detected on the poles. Spent the rest of the time optimizing this. 

To Do:
* Continue studying and working on OpenCV tutorials and project.

<br />

### June 25, 2021 (Day 19)
Updates:
* Continued optimizing the program. Results can be found [here](https://drive.google.com/drive/folders/1sPCrQWO7bUhgc-LEFQDKvdJ1INRbq5lp?usp=sharing) comparing different results with and without blurring. 
* Finalized the Jupyter Notebook. This can be found [here](https://drive.google.com/drive/folders/1sPCrQWO7bUhgc-LEFQDKvdJ1INRbq5lp?usp=sharing). 
* Created a separate Python program which can be ran quickly. I created fixed ROI regions, so it can be consistent for every image. This can be found [here](https://drive.google.com/drive/folders/1sPCrQWO7bUhgc-LEFQDKvdJ1INRbq5lp?usp=sharing). The program is capable of detecting lines for a separate image with similar lighting and snow conditions. 
* Looked into feature extraction methods for images. One feature that can be extracted is color. That can be useful for identifying parameters. 
* Source: [Color Identification using KMeans and OpenCV](https://www.kaggle.com/shubhanshugupta/color-identification-using-kmeans-and-opencv)

To Do:
* Continue studying and working on OpenCV tutorials and project.

<br />

## Week 5: Extracting Color as a Feature to Improve Parameterization 

<br />


### June 28, 2021 (Day 20)
Updates:
* Organized files, images, and programs in desktop and Drive. Updated links on Logs. 
* Worked with K-means algorithm from Friday to detect dominant color for images. The JN can be found [here](https://drive.google.com/drive/folders/10WqOMgO-E2BctzvELRWiE6GrZ9vTzP2F?usp=sharing). The results show that images with similar dominant hue were detected by the first line detection program created. However, changes in weather or lighting may affect the line detections, even with similar dominant hue. Images with different hue dominant could not have lines detected. The JN can be found [here](https://drive.google.com/drive/folders/10WqOMgO-E2BctzvELRWiE6GrZ9vTzP2F?usp=sharing).
* I uploaded the results onto a PowerPoint, which can be found [here](https://drive.google.com/drive/folders/10WqOMgO-E2BctzvELRWiE6GrZ9vTzP2F?usp=sharing). This will be presented in tomorrow's CV meeting.

To Do:
* Continue studying and working on OpenCV tutorials and project.

<br />

### June 29, 2021 (Day 21)

Updates:
* Meeting with Computer Vision Group. Discussed results found yesterday and improvements to be made for extracting features from images. Dividing the image into regions and using K-means may be one way to improve model.
* Looked into 'chunking.' Colin sent me a [JN](https://github.com/waggle-sensor/anomaly-detection/blob/main/.ipynb_checkpoints/Anomaly%20Detection%20(PCA)-checkpoint.ipynb) on something he worked on with chunking/compression/PCA.
* Image Chunking Sources:
    (1) [How do you split a list into evenly sized chunks?](https://stackoverflow.com/questions/312443/how-do-you-split-a-list-into-evenly-sized-chunks)
    (2) [Image Processing](https://examples.dask.org/applications/image-processing.html)
    (3) [How to split image into small blocks, process on them and then join all the blocks together again?](https://answers.opencv.org/question/173852/how-to-split-image-into-small-blocks-process-on-them-and-then-join-all-the-blocks-together-again/)
    (4) [Efficiently splitting an image into tiles in Python using NumPy](https://towardsdatascience.com/efficiently-splitting-an-image-into-tiles-in-python-using-numpy-d1bf0dd7b6f7)

To Do:
* Continue studying and working on OpenCV tutorials and project.

<br />

### June 30, 2021 (Day 22)

Updates:
* Attended seminar on 'Pathway to a Science Career Panel Seminar' by Dr. Kevin Brown.
* Decided to test out ROIs for feature extractions before diving deeper into image chunking. The dominant color from each ROI will be extracted as a feature. 
* Looked into ways to convert RGB data to usable categorical data. Found a way to convert RGB to labels by finding the closest color using Webcolors Python package. [Source](https://predictivehacks.com/how-to-use-rgb-codes-as-features-in-a-machine-learning-algorithm/).
* Incorporated Webcolors function into the RGB Color/Feature Extraction program. 

To Do:
* Continue studying and working on OpenCV tutorials and project.
* Find out how to save/read multiple images from a file onto Python.

### July 1, 2021 (Day 23)

Updates:
* Meeting with larger CV group. Discussed progress for this week.
* Found a way to easily load all images from a folder into a list using Glob Package. This will make the process of extracting features from multiple images easier and faster. [Source](https://stackoverflow.com/questions/30230592/loading-all-images-using-imread-from-a-given-folder).
* Incorporated Glob function and Pandas into the RGB Color/Feature Extraction program. 
* Acquired data from a smaller image dataset before moving to a larger image dataset (50 photos). The JN and the CSV file containing the extracted color labels for the larger dataset can be found [here](https://drive.google.com/drive/folders/10YVwwTP2-Gk79IVNf2VXBT-IOyueCAaH?usp=sharing). 
* From the results, we can see that images containing similar color labels (through closest distance measure) exhibit similar lighting and weather. However, in some instances, two photos can have very similar color labels but drastically different weather and lighting. For instance, NEON.D19.HEAL.DP1.00042_2017_09_30_114505.jpg contains the labels 'dimgray', 'slategray', and 'dimgray.' There is snow on the ground and partly cloudy in the image. On the otherhand, NEON.D19.HEAL.DP1.00042_2017_09_01_060006.jpg contains the labels 'dimgray', 'gray', and 'dimgray.' There is grass and no snow in the photo. 
* Because of this result, I decided that extracting colors from the ROIs are not enough. Thus, I decided to split the images into 4x4 chunks, extracting the color from each chunk. The JN and the CSV file containing the extracted color labels can be found [here](https://drive.google.com/drive/folders/10YVwwTP2-Gk79IVNf2VXBT-IOyueCAaH?usp=sharing). 

To Do:
* Continue studying and working on OpenCV tutorials and project.
* Analyze the larger dataset. Find out how to classify data.

### July 2, 2021 (Day 24)

Updates:
* Still followed and maintained the idea that images with similar weather/lighting conditions will possess similar color labels. Through analyzing the datasets, I found the dataset containing only ROIs to be more suceptible to errors, primarily with the color gray. Several images in September possess the dominant colors for the ROIs to be gray, even when there is no snow present. This is unfavorable for the classification algorithm.
* The data set with chunked data is obviously more robust as greater amount of features was gathered from all over the image: the dominant color labels are more diverse. Images with no snow contain color labels only present when there is no snow. Yet, the only downside is that this can be computationally expensive to generate and run models on. 
* Separated the images visually by perceived color (manually by eye) into different folders. This will aid in finding out similarities in color labels among images in the same folder (which will later help in developing the right program to run on these images to find lines). This can be found [here](https://drive.google.com/drive/folders/1LqoVygZs-KuCaWYdyFFLKL7oy7XkA-yT?usp=sharing).
* Created and finished presentation of results for Tuesday, which can be found [here](https://drive.google.com/drive/folders/1JtmTLseZsukvcth7h0NPWmNGSchqn8Y8?usp=sharing).

To Do:
* Continue studying and working on OpenCV tutorials and project.

<br />

## Week 6: Creating Programs Capable of Line Detection Among Different Conditions/Parameters

<br />

### July 6, 2021 (Day 25)
Updates:
* Meeting with Computer Vision Group. Presented results and discussed alternative methods to the ROI and Chunking methods. One suggestion would be to extract the color labels only for the bottom four chunks in the 4x4 image. This method is robust since the bottom of images contain less noise and objects compared to the rest of the image. 
* Looked into the alternative. Decided that including the ROIs in the data would be also important since we would be detecting lines from those areas. The proposed optimized feature extraction algorithm would include seven areas in the image where color labels will be attained: the bottom four regions (4x4) and the three ROIs.
* The JN for the above described algorithm can be found [here](https://drive.google.com/drive/folders/1JtmTLseZsukvcth7h0NPWmNGSchqn8Y8?usp=sharing) along with the dataset corresponding to it. 
* Began developing and refining parameters for line detection of images resembling snow_test.jpg (i.e. images which are cloudy, contain snow, and predominantly contain dim gray labels). Images containing 'dim gray' label with no snow could be filtered out by their respective 'green' or 'brown' labels.  
* Ran into issues with making the line detection algorithms more robust to encompass numerous images. Looked into ways to improve accuracy of line detection, not specifically to createFastLineDetector() method. Reading the documents from OpenCV and examples of other users applying line detection techniques led me to look into adding a separate canny method, erode method, and dilate method. This made the lines detected by the createFastLineDetector() method more crisp and actually on the pole.
* Sources: 
    (1) [Fast line detector](https://docs.opencv.org/4.5.2/df/ded/group__ximgproc__fast__line__detector.html)
    (2) [Connecting ends of edges openCV](https://stackoverflow.com/questions/65681384/connecting-ends-of-edges-opencv)
    (3) [https://docs.opencv.org/master/db/df6/tutorial_erosion_dilatation.html](https://docs.opencv.org/master/db/df6/tutorial_erosion_dilatation.html)
    (4) [How to detect lines in OpenCV?](https://stackoverflow.com/questions/45322630/how-to-detect-lines-in-opencv)
* Although the lines improved, the program was only applicable to one image. It would not apply to the other images despite several adjustments to the parameters.

To Do:
* Continue studying and working on OpenCV tutorials and project.

### July 7, 2021 (Day 26)
Updates:
* Attended seminar on 'Creating Effective Oral and Poster Presentations' by Dr. Bob Boomsma.
* Had one-on-one midpoint questionaire interview with Dr. Todd Munson.
* Read deeper into the [documents](https://docs.opencv.org/4.5.2/df/ded/group__ximgproc__fast__line__detector.html) for createFastLineDetector(), where I realized the errors in the parameters of the actual function. The parameters for createFastLineDetector() are:

    _length_threshold	10 - Segment shorter than this will be discarded
    _distance_threshold	1.41421356 - A point placed from a hypothesis line segment farther than this will be regarded as an outlier
    _canny_th1	50 - First threshold for hysteresis procedure in Canny()
    _canny_th2	50 - Second threshold for hysteresis procedure in Canny()
    _canny_aperture_size	3 - Aperturesize for the sobel operator in Canny(). If zero, Canny() is not applied and the input image is taken as an edge image.
    _do_merge	false - If true, incremental merging of segments will be performed

The original code for the createFastLineDetector (which can be found in the log for Day 19) contained the parameters '50, 100, 5, 5, 3, True.' These parameters were faulty, and obviously would lead to errors in future codes and for line detection for the following reasons:
    (1) The values for the first and second hysteresis are too low and inaccurate. The actual values can be determined through the canny track  bar program, which was initially mentioned and used in the log for Day 8. The canny trackbar program allows the user to select the best canny thresholds based on the canny output they see. The oriignal code can be found [here](https://drive.google.com/drive/u/1/folders/1oUQMWgmphOGV-kxji74zP_XyLX4kVBNS). 
    (2) Since we implemented canny separately, the canny components for the createFastLineDetector should be nulled. This can be simply done by applying '0' to _canny_aperture_size. The other canny parameters can have any positive integer as it would ultimately not affect the function.
See the JNs for examples on his these are applied [here](https://drive.google.com/drive/folders/1U5mALmj5rIvw-5iQEtOwAOP6eC754IiR?usp=sharing).
* Developed a pipeline for adjusting parameters for line detection of images:
    (1) Organize images by similarities in color (by eye) and by color labels. 
    (2) For each folder containing images:
        (1) Choose one representative image.
        (2) Run the canny trackbar method to determine canny parameters.
        (3) Assume the parameters for blurring as (1,1) and the iterations for dilation and erosion as 1.
        (4) Run the line detection program. Redo step 3 by adjusting each of the parameters. Repeat until lines are detected. 
* Lines were detected for dimgray, royalblue, and steelblue images. The JNs and sample results can be found in the JNs.
* Created and finished presentation of results for Thursday, which can be found [here](https://drive.google.com/drive/folders/1-oNN3Vg3TZgLzT34YXynW1c1hrGq4ccf?usp=sharing).

To Do:
* Continue studying and working on OpenCV tutorials and project.

### July 8, 2021 (Day 27)
Updates:
* Meeting with larger CV Group. Discussed progress for this week.
* Completed the JNs for the remaining colors: gray, darkslateblue, and slategray. The JNs can be found [here](https://drive.google.com/drive/folders/1-oNN3Vg3TZgLzT34YXynW1c1hrGq4ccf?usp=sharing). Images containing 'no snow' and images taken at 'night' will have their own respective programs which will be developed later. 
* All JNs are capable of detecting lines for most images in their respective colors. There are weaknesses:
    (1) Inclement Weather: When there is heavy precipiation (i.e. snow), the poles are not as visible and the thus the lines cannot be detected.
    (2) Not enough snow/Patches on the ground: Sometimes there are patches in the snow which adds more noise in the image. 
    (3) Shadows: Shadows from nearby buildings and structures change the dominant color labels for the ROIs. Most of the time, it makes the poles not visible for the line detector to detect. 
    (4) Images with different weather containing similar color labels.
* There are in total 8 labels: dimgray, royalblue, steelblue, gray, darkslateblue, slategray, no snow, and night. 
* Attended 'Office Hours' session with Sean on Plugin Development.

To Do:
* Continue studying and working on OpenCV tutorials and project.

### July 9, 2021 (Day 28)
Updates:
* Developed initial program for classifying images using Sci-kit Learn ML models. 
* There were prerequisites that need to be done first.
    (1) Created labels for the images in the dataset based on the log from yesterday. The new dataset can be found [here](https://drive.google.com/drive/folders/1j2gwzKOHwOaJ_uzTDHpv18HLCM21Ub_C?usp=sharing).
    (2) Label encode data.
* Create PowerPoint for Midpoint presentation on Monday.

To Do:
* Continue studying and working on OpenCV tutorials and project.




<br />

## Week 7: Contour Detection

<br />



### July 12, 2021 (Day 29)
Updates:
* Presented Midpoint PowerPoint to entire group. The PowerPoint can be found [here](https://drive.google.com/drive/folders/1jrV_0i8QX6UwJtTfbUvFFpf6ocmNoIms?usp=sharing). 
* Talked with Nicola on project progress and goals. Resinstated that we need to create labels for the poles, so having lines on the poles is not enough.
* Ideally we want the lines to create a box around the poles. However, this may not be possible for two reasons: (1) the orientation of the poles makes it difficult to detect parallel lines, (2) the line detector views the pole as one large line. Somes results can be found [here](https://drive.google.com/drive/folders/1jrV_0i8QX6UwJtTfbUvFFpf6ocmNoIms?usp=sharing).
* Looked into ways to improve object detection using edges and lines. Stumbled upon a paper which uses a technique involving contouring to identify utility poles. The paper 'Image Analysis-Based Automatic Utility Pole Detection for Remote Surveillance' can be found [here](https://ieeexplore-ieee-org.proxy.library.emory.edu/document/7371267). 
* The author's approach can be described as followed: 
    (1) Mean-shift segmentation (blob extraction)
    (2) Quadrilateral extraction using noisy edges
    (3) Shortlisting trapeziums
    (4) Orientation-based clustering of trapezium
    (5) Context based foreground detection
* I think the authors' quadrilateral extraction may be most useful for my project. Will be helpful in finding and extrapolating poles due to noisy edges and backgrounds.

To Do:
* Continue studying and working on OpenCV tutorials and project.

### July 13, 2021 (Day 30)
Updates:
* Developed JNs for contour detection. Since most contours are incomplete (due to noise), the minAreaRect() function is helpful in creating a box encompassing it. The function minAreaRect() was compared to results generated generated from boundRect().
* Sources: 
    (1) [Creating Bounding boxes and circles for contours](https://docs.opencv.org/4.5.2/da/d0c/tutorial_bounding_rects_circles.html)
    (2) [Difference between “Edge Detection” and “Image Contours”](https://stackoverflow.com/questions/17103735/difference-between-edge-detection-and-image-contours#:~:text=if%20it%20helps%2C%20you%20can,need%20to%20be%20closed%20curves.)
    (3) [Python opencv minAreaRect generates a minimal bounding rectangle](https://www.programmersought.com/article/3831529592/)
    (4) [OpenCV Minimum Area Rectangle](https://theailearner.com/tag/cv2-minarearect/)
    (5) [What is the output of minAreaRect(contours)](https://stackoverflow.com/questions/57967420/what-is-the-output-of-minarearectcontours)
    (6) [Improve image segmentation to create a closed contour surrounding my object](https://stackoverflow.com/questions/54681136/improve-image-segmentation-to-create-a-closed-contour-surrounding-my-object)
* Luckily, the work I done earlier dividing the images into groups based on dominant color did not go to waste. I still need to parameterize the contour methods and colors/lightings remain factors to consider.
* The new algorithm involves detecting contours after performing Canny edge detection. One metric for finding the contour for the pole is to use the length of the contours as a metric and finding the maximum length.
    (1) Change the image to grayscale.
    (2) Implement blur filter.
    (3) Implement canny transformation.
    (4) Implement dilate transformation.
    (5) Find contours.
    (6) Determine if contours can be found. If yes, continue.
        a) If no, return nothing End.
    (7) Find contours and create minimum-area rectangle. 
    (8) Determine if rectangle meets conditions (i.e., it actually detects the pole). 
    If yes, continue.
        a) If no, return nothing End.
    (9) Pole detected and annotated. End.
* The JNs for and the results from this algorithm can be found [here](https://drive.google.com/drive/folders/1BVH0TnKekx930N4GnlHSlkMW-xBiNKlw?usp=sharing).
* Created OverLeaf for project report and shared with Nicola.

To Do:
* Continue studying and working on OpenCV tutorials and project.

### July 14, 2021 (Day 31)
Updates:
* Attended seminar 'Special Presentation: Science Innovations for a Circular Economy Initiative at Argonne' by Dr. Massimilano Delferro.
* Attended Writing Coach session on Writing Abstracts by Dr. Boomsma.
* Attended student connects session.
* Met with Nicola for Office Hours to discuss updates, results, and issues with latest contour method. 
* Issues that should be addressed and resolved: (1) The leftmost pole cannot be detected properly because of the structure behind it. (2) There are objects (thermometers, shadows, etc) that may interfere with how the rectangle is formed. Some cases, as seen in results, the rectangles encapsulate the nearby objects. 
* Looked into ways to improve contour detection. 
* Sources: 
    (1) [How to merge contours in opencv?](https://www.py4u.net/discuss/240811)
    (2) [Improve rectangle contour detection in image using OpenCV](https://stackoverflow.com/questions/57125879/improve-rectangle-contour-detection-in-image-using-opencv)
    (3) [https://stackoverflow.com/questions/42721213/python-opencv-extrapolating-the-largest-rectangle-off-of-a-set-of-contour-poin](https://stackoverflow.com/questions/42721213/python-opencv-extrapolating-the-largest-rectangle-off-of-a-set-of-contour-poin)
* Google searches led me to think about ways to mute the background / enhance the foreground. Adaptive thresholding was a popular method, but parameterizing all of that would have been really cumbersome. Hence, I looked into the Otsu Binarization method. 
* Sources: 
    (1) [How to use the OTSU Threshold in opencv?](https://stackoverflow.com/questions/17141535/how-to-use-the-otsu-threshold-in-opencv)
    (2) [Otsu thresholding — image binarization](https://hbyacademic.medium.com/otsu-thresholding-4337710dc519)
* I implemented this into some JNs. The JNs and results can be found [here](https://drive.google.com/drive/folders/1inq1wUoJiNyAbh1tr-tUVJ02WmBMQr6l?usp=sharing). The algorithm is very similar to the Canny-Contour method except replacing the Canny portion.
* Found a way to detect edges through Canny without parameters. [Source](https://www.pyimagesearch.com/2015/04/06/zero-parameter-automatic-canny-edge-detection-with-python-and-opencv/).

To Do:
* Continue studying and working on OpenCV tutorials and project.

### July 15, 2021 (Day 32)
Updates:
* Created presentation and attended CV meeting. The PowerPoint can be found [here](https://drive.google.com/drive/folders/1ggGn8BYL7ohnxapO-o2qJCfECif_ca54?usp=sharing).
* Looked into alternative ways of detecting contours, which led me to think about forms of image segmentation techniques. I was particularly interested on Means-shift segmentation (mentioned previously by paper) and K-means clustering segmentation (I was familiar with K-means). 
* Sources: 
    (1) [Tutorial 3: Image Segmentation](https://ai.stanford.edu/~syyeung/cvweb/tutorial3.html)
    (2) [Object detection via color-based image segmentation using python](https://towardsdatascience.com/object-detection-via-color-based-image-segmentation-using-python-e9b7c72f0e11#:~:text=Contours,and%20object%20detection%20and%20recognition.)
    (3) [To Do:Segmenting images and mean shift](http://luthuli.cs.uiuc.edu/~daf/courses/CS-498-DAF-PS/Segmentation.pdf)
    (4) [Image Segmentation using K Means Clustering](https://www.geeksforgeeks.org/image-segmentation-using-k-means-clustering/)
    (5) [Introduction to Image Segmentation with K-Means clustering](https://www.kdnuggets.com/2019/08/introduction-image-segmentation-k-means-clustering.html)
* Developed a JN for K-means. The JN and results can be found [here](https://drive.google.com/drive/folders/1ggGn8BYL7ohnxapO-o2qJCfECif_ca54?usp=sharing).
* Seongha shared me her [Git repository](https://github.com/waggle-sensor/solar-irradiance-estimation) for UNet. 
* Sean shared me his [Git repository](https://github.com/seanshahkarami/neon-snow-dataset/tree/main/) on previous work for pole labeling. 

To Do:
* Continue studying and working on OpenCV tutorials and project.

### July 16, 2021 (Day 33 + Weekend)
Updates:
* Worked on revamping and finalizing the pole detection algorithm. 
* The proposed flowchart would look like this:
    (1) Import Image
    (2) Extract colors and label image (CANNY, OTSU, NONE).
    (3) Based on labels, the labeled task will be performed on the image. (ex: if labeled 'CANNY,' the Canny-contour method will be performed on image.)
    (4) If conditions are not met after the tasks have been performed, the image will be processed by K-Means method. 
    (5) Return annotated image. End. 
* Developed the conditions for filtering out poor pole detections. 
* It appears dimgray, royal blue, and darkslate blue work best with Otsu-Contour, Steel Blue works best with Canny-Contour.
* Attained a 68.9% accuracy using all photos from the NEON [repository](https://phenocam.sr.unh.edu/webcam/browse/NEON.D19.HEAL.DP1.00042/) from December 2017. 1958 poles were imported and 1350 were detected. Note there were some poles that appeared in images that were taken at night. The program and some results can be found [here](https://drive.google.com/drive/folders/1jPT3-r_vg5lbR1WBx13pHPu-ygEa0-DH?usp=sharing). The colors of the annotations are appropriately labeled: Red = Canny, Green = Kmeans, Blue = Otsu. 
* Ignore the 'canny' on all of the contour images. Not all the images were processed with Canny-Contour. This is an error in the code. 
* Note: the leftmost pole was not cropped and inputted into algorithm as it would achieve very poor segmentation due to the structure in the background.

To Do:
* Continue studying and working on OpenCV tutorials and project.

<br />

## Week 8: U-Net Training and Testing 

<br />


### July 19, 2021 (Day 34)
Updates:
* Included function which masks the image in the pole detection code. White pixels represent the pole is present. Black pixels represent the pole is not present. This will be useful for the CNN image segmentation. 
* The .py code is available on [GitHub](https://github.com/waggle-sensor/summer2021/tree/main/Li/project_code/pole_extraction_algorithm) and will be updately consistently there. 
* Used the labeled images from Day 33 as the training set for the U-Net model. Samples of these images can be found in the results folder from 2021.07.16. The complete training data will be found in a compressed folder.
* Fixed bugs with pole detection algorithm. Added comments and improved readability of code.
* Created PowerPoint for tomorrow's presentation. 
* Note: I call the algorithm by a lot of names: pole detection, pole extraction, pole labeling... they indicate the same program. 

To Do:
* Continue studying and working on OpenCV tutorials and project.

### July 20, 2021 (Day 35)
Updates:
* Presented results to CV group. PowerPoint can be found [here](https://drive.google.com/drive/folders/16lsegCAwpMYxdfE9sN4FO3LkOmycTwgp?usp=sharing).
* Worked with Seongha on running U-Net CNN for my training set. Was not able to run directly on my home laptop, so we resorted to using Docker. Was successful in training a dataset of 1350 masked images. 
* Checkpoints generated from training were saved to be used as models for testing.
* The testing model only has images and labels as inputs. I asked Seongha how we can measure/determine scores like accuracy. We may have to resort to examining the pixel differences or visually checking them out.
* Read and learned about the U-Net Model.
* Sources:  
    (1) [U-Net: Convolutional Networks for Biomedical Image Segmentation](https://arxiv.org/abs/1505.04597)
    (2) [Understanding Semantic Segmentation with UNET](https://towardsdatascience.com/understanding-semantic-segmentation-with-unet-6be4f42d4b47)
    (3) [U-Net](https://towardsdatascience.com/understanding-semantic-segmentation-with-unet-6be4f42d4b47)

To Do:
* Continue studying and working on OpenCV tutorials and project.

### July 21, 2021 (Day 36)
Updates:
* Attended seminar 'How to Establish Your Personal Brand' by Leslie Krohn.
* Attended student connects session.
* Took a break from grinding out code and worked on writing the final paper. Finished introduction and parts of methods.
* Used Seongha's [paper](https://www.mdpi.com/2073-4433/12/3/395) and the earlier [papers](https://github.com/waggle-sensor/summer2021/tree/main/Li/Readings) as guides for my writing. 
* Needed images for the testing set, so I ran the pole detection algorithm on images from December 2018. The algorithm did not perform as well as it did on December 2017. This was probably due to the patchier snow/grass (perhaps not enough snow?). The results from the contouring and masking can be found [here](https://drive.google.com/drive/folders/1dY9kPMZOofkoJc5kzp3vQOK8BWiChIIM?usp=sharing). 1141 images were inputted, two poles from each image (2282 total), including images at night. 975 poles labeled (42.7%) with false positives. 
* The images and labels from this run will be used for the testing.
* Created PowerPoint for tomorrow's meeting.

To Do:
* Continue studying and working on OpenCV tutorials and project.

### July 22, 2021 (Day 37)
Updates:
* Presented PowerPoint in CV meeting. PowerPoint can be found [here](https://drive.google.com/drive/folders/1gvSs-eS7FzpGXEmyoWoj8tFw6msuTy_I?usp=sharing).
* Worked with Seongha in testing the UNet CNN. I only tried it on a handful of images since I have not optimized her code, but the testing was successful. The generated predictions were able to detect the poles in the testing images. Some results can be found [here](https://drive.google.com/drive/folders/1gvSs-eS7FzpGXEmyoWoj8tFw6msuTy_I?usp=sharing).
* The U-Net code for training [GitHub](https://github.com/waggle-sensor/summer2021/tree/main/Li/project_code/unet_training) and [testing](https://github.com/waggle-sensor/summer2021/tree/main/Li/project_code/unet_testing) can be found on GitHub and will be updately consistently there. Additional logs and generated checkpoints will also be saved there, too.
* Attended Office Hours session with Sean to start initial stages of plug-in. Session was very productive and I was able to have some code written. Will need to ask Seongha for clarification on how to load the UNet model properly.  

To Do:
* Continue studying and working on OpenCV tutorials and project.

### July 23, 2021 (Day 38 + Weekend)
Updates:
* Seongha showed me how to load the model correctly into the plugin. Encounter other issues that I will need to ask Sean.
* Modified Seongha's testing code to be more suitable for the purpose of masking poles. The updates can be found on GitHub. 
* Worked on the last portion of my project, which is the distance measurement. 
* Developed small program which can find the minimum white pixel of the pole. (1) Found a contour (pole) (2) Detect contour min. This can be found [here](https://drive.google.com/drive/folders/1d91j2u1Xeuxkxy2E-p7l1-P9MtC_g6S0?usp=sharing).
* Compiled more images of poles in the snow to create masks of. Images were taken from the same NEON database from winters of 2017/2018 and 2018/2019. This would increase the diverity of the poles in the images and hopefully improve the model training (and ultimately testing. About 4000 images were collected.
* Worked on final report.

To Do:
* Continue studying and working on OpenCV tutorials and project.

<br />

## Week 9: More Testing and Wrapping Up 

<br />

### July 26, 2021 (Day 39)
Updates:
* Will be dedicating most of this week to finalizing the deliverables.
* Collected 1000 images to be run through the pole extraction algorithm. The labels and images will be used as the new training data. The new training data can be found [here](https://drive.google.com/drive/folders/1Va5ZwZXbx-t6TaKRWfD0FRe6twkRqNYt?usp=sharing) in a compressed folder.
* A larger assortment of images were run through pole extraction algorithms from the winters of 2017/2018 and 2018/2019. This was to generate cropped images and labels (for comparison).
* 450 randomly selected cropped images will be used as the testing set. The new testing data can be found [here](https://drive.google.com/drive/folders/1Va5ZwZXbx-t6TaKRWfD0FRe6twkRqNYt?usp=sharing) in a compressed folder.
* Finished one draft of the paper, not including the results, discussion, and abstract. Will be doing revisions throughout the week.

To Do:
* Continue studying and working on OpenCV tutorials and project.

### July 27, 2021 (Day 40)
Updates:
* Discussed updates during CV group meeting.
* Created a small tutorial pdf for how to submit a blog draft on the Sage site per request of Raj.
* Fixed a small bug with naming the contour image files in the pole extraction algorithm. Updated version should be available on GitHub.
* Ran the testing set using the model. Results can be found [here](https://drive.google.com/drive/folders/1Va5ZwZXbx-t6TaKRWfD0FRe6twkRqNYt?usp=sharing).
* The results were overall very good. The model tends to not overestimate compared with the pole extraction algorithm. Additionally, it was able to detect the rods at times where the algorithm fails. Weaknesses of the model occur when the images have poor visibility or high noise. 
* Started working on presentation for group meeting tomorrow.
* Did first round of major edits in the final report. 

To Do:
* Continue studying and working on OpenCV tutorials and project.

### July 28, 2021 (Day 41)
Updates:
* Attended seminar 'Open Q&A on Deliverables/Learning Off the Lawn Overview'.
* Finalized PowerPoint for today's presentation. The PowerPoint can be found [here](https://drive.google.com/drive/folders/1Kz2cSS5V6bX5rmeW7YFT_LrsUN9Xp5Ms?usp=sharing).
* Presented my final presentation in front of the group. 
* Will be modifying this a bit for the actual SULI presentation next week.

To Do:
* Continue studying and working on OpenCV tutorials and project.

### July 29, 2021 (Day 42)
Updates:
* Attended brief meeting with CV group.
* Cleaned up and made sure all links in Daily Log are updated and files are properly uploaded onto Google Drive/GitHub.
* Figured out how to create references on OverLeaf. Overcame one annoying bug stemming from one citation of a .pdf file. 

To Do:
* Clean up work. 
* Finish deliverables.

### July 30, 2021 (Day 43)
Updates:
* Wanted to find a way to calculate some form of accuracy metric for the UNet model. Found a site which explained the differnet metrics [here](https://www.jeremyjordan.me/evaluating-image-segmentation-models/).
* Created a dataset of 100 good labeled images (no overestimations, 'perfect') for the ground truth and their corresponding U-Net predictions as the predicted images
* Developed small program for calculating mIoU. Can be found on GitHub [here](https://github.com/waggle-sensor/summer2021/tree/main/Li/project_code/validation).
* The mIoU score was 0.565. 
* Finished most of the paper on Overleaf, including figures and citations. Need abstract.

To Do:
* Clean up work. 
* Finish deliverables.

<br />

## Week 10: Final Week

<br />


<!-- 
https://github.com/dloperab/PyImageSearch-CV-DL-CrashCourse
[Day 1: Face detection with OpenCV and deep learning](https://www.pyimagesearch.com/2018/02/26/face-detection-with-opencv-and-deep-learning/)
[Day 2: OpenCV Tutorial: A Guide to Learn OpenCV](https://www.pyimagesearch.com/2018/07/19/opencv-tutorial-a-guide-to-learn-opencv/)
[Day 3: How to Build a Kick-Ass Mobile Document Scanner in Just 5 Minutes]()
[Day 4: Bubble sheet multiple choice scanner and test grader using OMR, Python and OpenCV](https://www.pyimagesearch.com/2016/10/03/bubble-sheet-multiple-choice-scanner-and-test-grader-using-omr-python-and-opencv/)
[Day 5: Ball Tracking with OpenCV](https://www.pyimagesearch.com/2015/09/14/ball-tracking-with-opencv/)
[Day 6: Measuring size of objects in an image with OpenCV](https://www.pyimagesearch.com/2016/03/28/measuring-size-of-objects-in-an-image-with-opencv/)
[Day 8: Facial landmarks with dlib, OpenCV, and Python](https://www.pyimagesearch.com/2017/04/03/facial-landmarks-dlib-opencv-python/)
[Day 9: Eye blink detection with OpenCV, Python, and dlib](https://www.pyimagesearch.com/2017/04/24/eye-blink-detection-opencv-python-dlib/)
[Day 10: Drowsiness detection with OpenCV](https://www.pyimagesearch.com/2017/05/08/drowsiness-detection-opencv/)
[Day 12: A simple neural network with Python and Keras](https://www.pyimagesearch.com/2016/09/26/a-simple-neural-network-with-python-and-keras/)
[Day 13: Deep Learning with OpenCV](https://www.pyimagesearch.com/2017/08/21/deep-learning-with-opencv/)
[Day 14: How to (quickly) build a deep learning image dataset](https://www.pyimagesearch.com/2018/04/09/how-to-quickly-build-a-deep-learning-image-dataset/)
[Day 15: Keras and Convolutional Neural Networks (CNNs)](https://www.pyimagesearch.com/2018/04/16/keras-and-convolutional-neural-networks-cnns/)
[Day 16: Real-time object detection with deep learning and OpenCV](https://www.pyimagesearch.com/2017/09/18/real-time-object-detection-with-deep-learning-and-opencv/)

-->

<!-- ## Heading 2
### Heading 3
#### Heading 4
##### Heading 5
###### Heading 6 -->
