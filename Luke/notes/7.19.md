## Notes

- Gave midpoint presentation to the group about my progress. I covered the working prototype of the pipeline in detail.
- To do
  - Write a post-processing script for the metrics that will be executed after the app has finished
  - Turn my previous water segmentation research into a working plugin that can be profiled
    - I am currently downloading the previous 14GB dataset that I worked with so that I can possibly re-train and re-test my algorithm
  - Incorporate live metric publishing into the profiling image

## Meeting Notes

- Questions
  - How do we account for apps that depend on other node services? (Say, the playback server)
    - Do we allow the developers to specify which "sidecar" containers to run alongside the app? This could be sent to the Jenkins pipeline as some kind of argument
- To do
  - Implement live metric reporting *(to provide them to Aji's controller)* through some pre-packaged solution. I will look into a solution that Sean suggested- Prometheus.
    - What metrics can we export live? Probably only simple system metrics (current CPU, RAM, GPU usages) or metrics exported by the app through pywaggle (*work in progress*)
  - Post-processing of metrics on the testbed after app completes
    - What is most relevant to scientists from the Tau/Nvprof outputs? They probably don't want the whole call stack, probably just the most expensive functions that could be potential bottlenecks.
    - What metrics can be timestamped as the app runs and which can't? Nvprof and/or Tau may not be able to have timestamps attached to their outputs, because they wait til the end of the app to dump their results.
  - Package my previous summer's research on water segmentation into a plugin that can be profiled
  - Test out other testbed devices?



