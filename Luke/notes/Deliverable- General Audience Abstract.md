In any scientific field, scientists need datasets and a system to collect them. The Sage team addresses this problem by providing scientists access to a wide network of sensor nodes. Scientists can harness the power of this network by deploying AI applications onto many nodes at once. However, it is a difficult problem to manage the execution of these AI applications on a single node, especially when the resource footprint of each app is unknown. My summer project has been to collaborate with my team on a software pipeline that can systematically assess the resource footprint (CPU/GPU usage, RAM usage) of an arbitrary AI application. To build this pipeline, I learned more about Linux system design, including how processes are managed by the kernel, how containers can be run, and how sockets transfer data. I gained experience working with system tools and drivers. Communication was key to my work, as I worked on just a small piece of a large project. I wrote multiple software interfaces that required me to know the detailed workings of software written by different developers. 

Not only did I gain technical experience with cutting-edge tools, but I learned more about the work culture of a national lab. The engineers and scientists who work on the Sage team are truly invested in their work, and their enthusiasm is infectious. My experience has further inspired me to consider grad school and a full-time job in research.

Scientists need data, and the Sage project delivers. If science is to be advanced, it will be through the help of AI and sensor nodes. I am proud to have worked on a project that is equipping this country's scientists with the resources they need to solve some of our world's biggest challenges.

