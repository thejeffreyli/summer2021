## Notes

- Trying to adapt my water segmentation algorithm to a plugin format that uses a live camera. I need to ask Sean about how to guarantee a certain frame stream FPS, or if that is even possible. I will want to use the 5fps model (after generating some test segmentations it looked like that model performed the best), but the model performs the best when it is receiving a buffer of frames that are spaced out in time according to 5fps. That amounts to 0.2s spacing per frame. Right now I am doing tests on how fast the stream can pull frames from a video file, but that still won't give me the best measurements on the live video performance.

  - I made a test script that shows me the FPS of running through the `Camera` interface with a test video and I get like 900fps which makes sense considering I am running it on my desktop.

- Talked with Yomi about getting the database setup with my Jenkinsfile. There was some disconnect between our work because I had assumed that Jenkins had full access to the host filesystem, but since Jenkins is containerized on the ECR, we need to share files on the host with it explicitly.

- Am currently working on a substitute to Sean's idea of incorporating a metrics interface to `pywaggle`. It looks like he will be too busy to implement that through pywaggle, so I might try to see if I can write my own solution. So far Prometheus looks easy to work with and I could write a wrapper for it so that developers could just import a metrics server object and spin that up. Then each node would have a Prometheus endpoint. The interface could look like this:

  ```
  from SageMetrics import SageMetricsServer
  
  s = SageMetricsServer()
  s.add("fps", SageMetrics.GAUGE)
  s.add("latency", SageMetrics.GUAGE)
  s.add(SageMetrics.METRIC_GPU_USAGE)
  s.add(SageMetrics.METRIC_MEM_USAGE)
  s.start()
  
  def some_inferencing_code( ... ):
  	time_at_request = time.time_ns()
  	...
  	s.report("latency", time_at_request - time.time_ns())
  	...
  ```

  