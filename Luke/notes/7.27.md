## Notes

- ECR Meeting Notes
  - I will need to meet with Yongho and Yomi sometime to talk about how to put metrics into the database. Previously, the system I had written in Jenkins was able to build a profiling image, rely on the shell script to launch the auxiliary tools and app, and then pull a tarball of the output folder to the server database. The new live metrics approach will require us to rethink the pipeline, because it will be the same pipeline that we record live performance and historic performance. How can we use the Prometheus client to export metrics to the database?
  - I can write a custom exporter into the client that will also export per-container memory usage and maybe also nvprof output? So when an app is closed, the Prometheus client is somehow alerted of the fact and exports the nvprof trace dump.



- Configuring a database solution around Prometheus
  - Should we distinguish a profiling "session" and live profiling as two modes of operation? For example, we will always want to export metrics from Python hooks that developers have specified, since those metrics (FPS, latency) will be essential for the edge controller to know. However, we won't always want to run `nvprof` or `Tau` with the application when it is being deployed onto a node.
  - There is no way to send files through Prometheus, as it is intended just for exporting raw numbers. How are we going to send nvprof / Tau traces under this system? Can we use Jenkins `stash/unstash` still?

