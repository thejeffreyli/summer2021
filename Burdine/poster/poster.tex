%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Dreuw & Deselaer's Poster
% LaTeX Template
% Version 1.0 (11/04/13)
%
% Created by:
% Philippe Dreuw and Thomas Deselaers
% http://www-i6.informatik.rwth-aachen.de/~dreuw/latexbeamerposter.php
%
% This template has been downloaded from:
% http://www.LaTeXTemplates.com
%
% License:
% CC BY-NC-SA 3.0 (http://creativecommons.org/licenses/by-nc-sa/3.0/)
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%----------------------------------------------------------------------------------------
%	PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------

\documentclass[final,hyperref={pdfpagelabels=false}]{beamer}
\usepackage{multirow}
\usepackage[orientation=portrait,size=a0,scale=1.4]{beamerposter} % Use the beamerposter package for laying out the poster with a portrait orientation and an a0 paper size
\usepackage{xcolor}
\usetheme{Local} % Use the I6pd2 theme suplied with this template
%\usepackage{extsizes}
\usepackage[english]{babel} % English language/hyphenation

\usepackage{amsmath,amsthm,amssymb,latexsym} % For including math equations, theorems, symbols, etc

%\usepackage{times}\usefonttheme{professionalfonts}  % Uncomment to use Times as the main font
%\usefonttheme[onlymath]{serif} % Uncomment to use a Serif font within math environments

\boldmath % Use bold for everything within the math environment

\usepackage{booktabs} % Top and bottom rules for tables

\graphicspath{{figures/}} % Location of the graphics files

\usecaptiontemplate{\small\structure{\insertcaptionname~\insertcaptionnumber: }\insertcaption} % A fix for figure numbering

%----------------------------------------------------------------------------------------
%	TITLE SECTION 
%----------------------------------------------------------------------------------------

\title{\Huge Online Anomaly Localization in \\ Images at the Edge} % Poster title

\author{Colin Burdine \hspace{1cm} (\texttt{cburdine@baylor.edu})} % Author(s)

\institute{SULI Intern $\mid$ Argonne National Laboratory $\mid$ MCS Division} % Institution(s)

\titlelogo{figures/argonne_logo}

%----------------------------------------------------------------------------------------
%	FOOTER TEXT
%----------------------------------------------------------------------------------------

\newcommand{\leftfoot}{bit.do/poster-PDP093} % Left footer text

\newcommand{\rightfoot}{PDP-093/SKPP/III/2018} % Right footer text

%----------------------------------------------------------------------------------------
%   ADDITIONAL MACROS:
%----------------------------------------------------------------------------------------

\newcommand{\tabimg}[2]{\begin{tabular}{c}\includegraphics[scale=#2]{#1}\end{tabular}}
\newcommand{\boxtabimg}[2]{\begin{tabular}{c}\fbox{\includegraphics[scale=#2]{#1}}\end{tabular}}

%----------------------------------------------------------------------------------------

\begin{document}

\addtobeamertemplate{block end}{}{\vspace*{2ex}} % White space under blocks

\begin{frame}[t] % The whole poster is enclosed in one beamer frame

\begin{columns}[t] % The whole poster consists of two major columns, each of which can be subdivided further with another \begin{columns} block - the [t] argument aligns each column's content to the top

\begin{column}{.02\textwidth}\end{column} % Empty spacer column

\begin{column}{.465\textwidth} % The first column

%----------------------------------------------------------------------------------------
%	INTRODUCTION
%----------------------------------------------------------------------------------------
            
\begin{block}{Introduction and Background}
\begin{itemize}
\item \textit{Image anomaly localization} is the task of locating uncommon objects in an image, if they exist.

\begin{itemize}
\item Many existing anomaly detection models are semi-supervised and offline, requiring large labeled datasets and human calibration to perform well.

\item In this research, we propose a novel ``self-taught" model that performs \textit{unsupervised online anomaly localization.}
\end{itemize}

\item \textit{Convolutional Autoencoders} (CAEs) are machine learning models commonly used for anomaly localization in images.  This research proposes a novel framework for deploying unsupervised convolutional autoencoders in an online edge computing setting.\\[4mm]

%\begin{itemize}
%
%\item There exist many mechanisms to improve unsupervised anomaly localization in the literature. We divide these mechanisms into two categories: \textit{regularizers} and \textit{false positive reducers}:\\[4mm]
%
%\item \textit{regularizers} help to avoid overfitting the training data, thereby allowing the model to generalize better on previously unseen images.
%
%\item \textit{False positive reducers} aim to ensure that an anomaly's deviation from the ``normal" data is statisticallly significant. In an unsupervised setting, they help to better distinguish between true anomalies and anomalies detected due to background noise.
%
%\end{itemize}
\end{itemize}
\end{block}


%----------------------------------------------------------------------------------------
%	METHODS
%----------------------------------------------------------------------------------------

\begin{block}{Methods}

\begin{itemize}
\item \textbf{Dataset}
\begin{itemize}
\item We used the NEON Phenocam dataset for Rocky Mountain National Park \\ (site \texttt{NEON.D10.RMNP.DP1.00033}) for the set of ``normal" images.\\
\begin{itemize}
\item The images were taken in the interval of May 1, 2021 to June 1, 2021.
\item ``Anomaly" images were added manually, using photo editing software.\\[6mm]
\end{itemize}
\end{itemize}
%\begin{figure}
%\includegraphics[scale=1.4]{figures/RMNP_timeline}
%\caption{A timeline of the anomalies added to the NEON RMNP Dataset.\qquad\qquad~}
%\end{figure}

\bigskip
\item \textbf {Model Architecture}\\[1cm]

\begin{figure}
\fbox{\includegraphics[scale=0.6]{figures/cae_diagram}}
\caption{Our proposed Convolutional Autoencoder model.}
\end{figure}

\bigskip
\item \textbf{Attention Expansion}

\begin{itemize}
\item As a form of regularization, we applied \textit{attention expansion loss}, which penalizes the model for making the latent features sensitive to small regions of the input image.

\item For each image $\mathbf{X}$ we computed an attention map $\mathbf{A_X}$ using the Grad-CAM algorithm, which packpropagates the latent features to the last convolutional layer in the encoder.

\item During training, the loss function we used for a reconstructed image $\widetilde{X}$ was
$$\text{loss} = \text{mean}[(\mathbf{X} - \widetilde{\mathbf{X}})^2] + w_{AE} \cdot \text{mean}[(1 - \mathbf{A_X})^2],$$
where the means are taken across all channels and pixels. We empirically selected the attention expansion weight $w_{AE} = $ 0.005.\\[6mm]
\end{itemize}

\item\textbf{Gamma Distribution Filter}

\begin{itemize}
\item To localize anomalies, we proposed a novel method which fitted the mean square error loss $(x_p)$ of each pixel to a \textit{exponential moving gamma distribution}, so that $x_p \sim \Gamma(\kappa_p(t), \theta_p(t))$ with time-dependent gamma parameters $\kappa_p(t), \theta_p(t)$.

\item To determine if a pixel is part of an anomaly, we performed a ``per-pixel p-value test" for a given approximate anomaly probability $\alpha$ close to 0.

\item This gamma distribution filter accounts for background noise in images, while also only requiring a constant number of parameters to be stored per pixel, making it ideal for edge computing systems with limited memory.\\[6mm]
\end{itemize}

\item\textbf{Simulated Online Training}
\begin{itemize}
\item Training of the model was divided into a \textit{calibration} and \textit{simulated online} phase.

\item In the \textit{calibration phase}, the model is trained on a small set of 100 training examples to avoid an initial high false positive rate. The parameters of the gamma distribution filter are also set.

\item After calibration, the model is deployed in a \textit{simulated online} phase where the model is given each sequential image in the dataset. For each image, the model performs small weight updates and small updates to the gamma distribution filter parameters. All detected anomalies are recorded during this phase.
\end{itemize}
\end{itemize}
\end{block}

%------------------------------------------------

\end{column} % End of the first column
\begin{column}{.03\textwidth}\end{column} % Empty spacer column
 
\begin{column}{.465\textwidth} % The second column

%------------------------------------------------
%---

%----------------------------------------------------------------------------------------
%	RESULTS
%----------------------------------------------------------------------------------------

\begin{block}{Results}

\begin{itemize}
\item\textbf{Use of the Gamma Distribution Filter}\\[6mm]

\begin{figure}
\fbox{\includegraphics[scale=1.2]{figures/gamma_filter}}
\fbox{\includegraphics[scale=1.2]{figures/gamma_filter_noise}}
\caption{Distribution of the mean reconstruction loss (left) and estimated \\
background noise in the form of a log-variance map (right).}
\end{figure}

\begin{itemize}
\item As illustrated in Figure 2, we observed that the reconstruction loss is best fitted by a gamma distribution, which justifies the use of the gamma distribution filter.

\item We also observed from the background noise map that some parts of the image vary more than others due to noise in the reconstruction loss. We verified that accounting for the background noise gives more robust predictions.\\[6mm]

\end{itemize}
\item\textbf{Prediction Localization}
\begin{figure}

\begin{itemize}
\item As shown in Figure 3, our model obtained qualitatively good anomaly localization. The bounding boxes shown were computed to enclose the contours of the anomalous pixels that were output from the gamma distribution filter.\\[6mm]
\end{itemize}
\includegraphics[scale=0.7]{figures/anomalies}
\caption{Examples of \textit{true positive} predictions generated by the model.\qquad\quad~}
\end{figure}

\item \textbf{Accuracy and Impact of Attention Expansion}\\[6mm]

\begin{figure}
\scriptsize
\begin{center}
\begin{tabular}{c c | c}
 & \normalsize{No Attention Expansion} & \normalsize{Attention Expansion}\\
\begin{tabular}{l}(a)\end{tabular} 
  & \begin{tabular}{c}\includegraphics[scale=0.45]{figures/acae_heatmaps_0}\end{tabular}
  & \begin{tabular}{c}\includegraphics[scale=0.40]{figures/acae_heatmaps}\end{tabular} \\
\begin{tabular}{l}(b)\end{tabular}
 & \begin{tabular}{c}\includegraphics[scale=1.06]{figures/neon_cae_roc}\end{tabular} 
 & \begin{tabular}{c}\includegraphics[scale=1.06]{figures/neon_acae_roc}\end{tabular} \\
 & \textbf{Area under Curve:  0.6371} & \textbf{Area under curve: 0.738} \\ 
\end{tabular}
\caption{Comparison of example attention maps (a) and ROC Curves (b) \\ with and without attention expansion.}
\end{center}
\end{figure}

\end{itemize}


\end{block}
\begin{block}{Conclusions}

\begin{itemize}

\item Anomaly localization, especially in an unsupervised online setting is a difficult task and requires a careful choice of model to perform well.
\item Despite this, we achieved a reasonable amount of success with an online CAE using novel techniques such as a gamma distribution fitler, as well as recently discovered techniques such as attention expansion. These techniques yielded an AUROC of 0.738.
\item We hope that future work can be done to improve upon the accuracy of this model in an unsupervised online setting.\\[2mm]
\end{itemize}

\end{block}
\end{column} % End of the second column

\begin{column}{.015\textwidth}\end{column} % Empty spacer column

\end{columns} % End of all the columns in the poster

%----------------------------------------------------------------------------------------
%----------------------------------------------------------------------------------------
%	CONCLUSION
%----------------------------------------------------------------------------------------



%----------------------------------------------------------------------------------------


\begin{tabular}{l c r }
\includegraphics[scale=0.16]{figures/doe_footer} & 
\hspace{50cm} & 
\includegraphics[scale=0.15]{figures/argonne_footer}\\[2mm]
\end{tabular}
\begin{columns}


\begin{tabular*}{\columnwidth}{@{\extracolsep{\stretch{1}}}*{3}{c}@{}}
\includegraphics[scale=0.8]{figures/doe_footer} & 
%{\color{white}
%\small\textbf{
%This research is funded by ... }
%}
& \includegraphics[scale=1.0]{figures/argonne_footer} \\[6cm]
\end{tabular*}
\end{columns}
\end{frame} % End of the enclosing frame
\end{document}
